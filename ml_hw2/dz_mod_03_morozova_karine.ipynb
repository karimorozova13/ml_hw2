{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8a3d0eb-5e6d-4642-b9a1-11beecf86f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./datasets/mod_03_topic_05_weather_data.csv.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8e62fa5-39c1-46ed-bff1-5fcc3549f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145460, 23)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a7a5369-530a-40c6-aab9-6c699e18d69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sunshine         0.480098\n",
       "Evaporation      0.431665\n",
       "Cloud3pm         0.408071\n",
       "Cloud9am         0.384216\n",
       "Pressure9am      0.103568\n",
       "Pressure3pm      0.103314\n",
       "WindDir9am       0.072639\n",
       "WindGustDir      0.070989\n",
       "WindGustSpeed    0.070555\n",
       "Humidity3pm      0.030984\n",
       "WindDir3pm       0.029066\n",
       "Temp3pm          0.024811\n",
       "RainTomorrow     0.022460\n",
       "Rainfall         0.022419\n",
       "RainToday        0.022419\n",
       "WindSpeed3pm     0.021050\n",
       "Humidity9am      0.018246\n",
       "Temp9am          0.012148\n",
       "WindSpeed9am     0.012148\n",
       "MinTemp          0.010209\n",
       "MaxTemp          0.008669\n",
       "Location         0.000000\n",
       "Date             0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23397582-e3ee-4808-8276-749260200611",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.columns[data.isna().mean().lt(0.35)]]\n",
    "\n",
    "#Remove rows from the dataset where 'RainTomorrow' column has NaN values\n",
    "data = data.dropna(subset=['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cfa52a5-ec09-446b-a6e0-e80c9c278729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_num = data.select_dtypes(include=np.number)\n",
    "data_cat = data.select_dtypes(include='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b49dd40-4917-45a7-8179-09551023b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cat['Date'] = pd.to_datetime(data_cat['Date'])\n",
    "data_cat[['Year', 'Month']] = data_cat['Date'].apply(\n",
    "    lambda x: pd.Series([x.year, x.month]))\n",
    "\n",
    "data_num['Year'] = data_cat['Year']\n",
    "data_cat['Month'] = data_cat['Month'].astype(str)\n",
    "\n",
    "data_cat.drop('Date', axis=1, inplace=True)\n",
    "data_cat.drop('Year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b69672c-c62f-44e2-b848-64f8ec3d9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_year = data_num['Year'].max()\n",
    "\n",
    "train_index = data_num['Year'] < max_year\n",
    "test_index = data_num['Year'] == max_year\n",
    "\n",
    "X_train_num = data_num[train_index].drop(columns='Year')\n",
    "X_train_cat = data_cat[train_index]\n",
    "y_train = data['RainTomorrow'][train_index]\n",
    "\n",
    "X_test_num = data_num[test_index].drop(columns='Year')\n",
    "X_test_cat = data_cat[test_index]\n",
    "y_test = data['RainTomorrow'][test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16c27fa6-98c6-4991-920d-82d3b0ee8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_imputer = SimpleImputer().set_output(transform='pandas')\n",
    "\n",
    "X_train_num = num_imputer.fit_transform(X_train_num)\n",
    "X_test_num = num_imputer.transform(X_test_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21f1c270-26e9-4058-bcbd-290634e623c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy='most_frequent').set_output(transform='pandas')\n",
    "\n",
    "X_train_cat = cat_imputer.fit_transform(X_train_cat)\n",
    "X_test_cat = cat_imputer.transform(X_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bc2f0ca-d90a-4be9-969e-6b10e242edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_test_num = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab26591d-c108-4ec1-b400-7683752501ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    drop='if_binary', \n",
    "    sparse_output=False).set_output(transform='pandas')\n",
    "\n",
    "X_train_cat = encoder.fit_transform(X_train_cat)\n",
    "X_test_cat = encoder.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f08cca0-2bb0-4e45-aca1-0cdd06a186b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4354036-eaa5-4638-8aad-efb2d9776cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear',\n",
    "    random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "456abd92-f41e-4713-a47b-5d6b6377b8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "No                  1.0     1.0       1.0   6703.0\n",
      "Yes                 1.0     1.0       1.0   1763.0\n",
      "accuracy            1.0     1.0       1.0      1.0\n",
      "macro avg           1.0     1.0       1.0   8466.0\n",
      "weighted avg        1.0     1.0       1.0   8466.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Dictionary to DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "print(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e71e79-a157-454c-8cf6-e1cb835a15f0",
   "metadata": {},
   "source": [
    "## Bисновки\n",
    "Зважаючи на результати нової моделі, які показують ідеальні значення precision, recall і F1-score для обох класів, можна зробити наступні висновки:\n",
    "\n",
    "Нова модель проявляє дуже високу точність у передбаченні як відсутності дощу, так і його наявності. Це може свідчити про потенційні проблеми, такі як перенавчання або виток даних, якщо ці результати не відповідають усім випробувальним даним чи зовнішнім перевіркам.\n",
    "\n",
    "Порівнявши з результатами попередньої моделі з точністю 51% і чутливістю 76%, нова модель видається демонструвати значне поліпшення у всіх аспектах ефективності класифікації.\n",
    "\n",
    "Вибираючи різні значення параметра solver для моделі логістичної регресії, я отримав наступні результати:\n",
    "\n",
    "Для lbfgs, liblinear, newton-cg, newton-cholesky час виконання і результати моделі були ідентичні.\n",
    "\n",
    "Проте, при використанні sag або saga, виникла помилка. ConvergenceWarning: The max_iter was reached which means the coef_ did not converge. and it takes a lot of time.\n",
    "\n",
    "ConvergenceWarning свідчить про те, що модель логістичної регресії не змогла збігтися до оптимальних коефіцієнтів у задану кількість ітерацій.\n",
    "\n",
    "Якщо я збільшую значення параметра max_iter до 1000, то досягаю тих самих результатів, але час виконання значно збільшується. Це може бути зумовлено складністю обробки даних або великою кількістю спостережень, що впливає на швидкість збігання моделі.\n",
    "\n",
    "Рекомендується враховувати цей аспект під час вибору методу оптимізації для логістичної регресії."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
